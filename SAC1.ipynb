{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76cfaee-af10-4766-a57e-6ebcd034d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c3c34a-5ee0-45b3-864e-08d22db2f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load SST-2 dataset\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Tokenize and format the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\", \"idx\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Save the tokenized dataset\n",
    "#tokenized_datasets.save_to_disk(\"sst2_tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a75a3-1ef1-425b-8793-226e87d081cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Split the tokenized dataset into train and validation sets\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "val_dataset = tokenized_datasets[\"validation\"]\n",
    "\n",
    "# Define DataLoaders for batching\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b172b-c0b3-4c12-989b-adf9aa1d8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Load BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",  # Pretrained model name\n",
    "    num_labels=2          # Number of output labels (positive/negative)\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model loaded on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e02992-6cb6-4705-888e-407418198cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "# Define loss function (implicitly handled in Hugging Face's Trainer API)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer: AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "num_epochs = 3\n",
    "num_training_steps = len(train_dataloader) * num_epochs\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Print training parameters\n",
    "print(f\"Number of training steps: {num_training_steps}\")\n",
    "print(f\"Optimizer: AdamW, Learning rate: {5e-5}\")\n",
    "print(f\"Scheduler: Linear decay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da329c92-1cd8-4c93-9d9b-a223bd678ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 3\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    for batch in train_dataloader:\n",
    "        # Move data to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Rename the 'label' key to 'labels'\n",
    "        batch[\"labels\"] = batch.pop(\"label\")\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Validation loop (optional for now)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            # Rename 'label' to 'labels'\n",
    "            batch[\"labels\"] = batch.pop(\"label\")\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Compute validation loss\n",
    "            val_loss += F.cross_entropy(logits, batch[\"labels\"]).item()\n",
    "\n",
    "            # Predictions and accuracy\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            correct += (preds == batch[\"labels\"]).sum().item()\n",
    "            total += batch[\"labels\"].size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Validation Loss = {val_loss / len(val_dataloader)}, Accuracy = {correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187ae13-705a-492f-b771-38505f6c0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load SST-2 dataset\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "val_dataset = dataset[\"validation\"]\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the validation set\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "tokenized_val_dataset = tokenized_val_dataset.remove_columns([\"sentence\", \"idx\"])\n",
    "tokenized_val_dataset.set_format(\"torch\")\n",
    "\n",
    "# Create a DataLoader\n",
    "val_dataloader = DataLoader(tokenized_val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d21a9-2e5c-4b94-8725-0d119fcae5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference loop\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        # Move data to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Rename 'label' to 'labels' to match the model's expectations\n",
    "        batch[\"labels\"] = batch.pop(\"label\")\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = finetuned_model(**batch)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        # Update accuracy metrics\n",
    "        correct += (predictions == batch[\"labels\"]).sum().item()\n",
    "        total += batch[\"labels\"].size(0)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy with fine-tuning: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4529c690-7a38-4794-ab94-a452ae24dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load SST-2 dataset\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "val_dataset = dataset[\"validation\"]\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the validation set\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = tokenized_val_dataset.remove_columns([\"sentence\", \"idx\"])\n",
    "tokenized_val_dataset.set_format(\"torch\")\n",
    "\n",
    "# Create DataLoader\n",
    "val_dataloader = DataLoader(tokenized_val_dataset, batch_size=16)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load Pretrained BERT (model2 without fine-tuning)\n",
    "model2 = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model2.eval()\n",
    "model2.to(device)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Move data to device\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            # Rename 'label' to 'labels'\n",
    "            batch[\"labels\"] = batch.pop(\"label\")\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # Update accuracy\n",
    "            correct += (predictions == batch[\"labels\"]).sum().item()\n",
    "            total += batch[\"labels\"].size(0)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    return correct / total\n",
    "\n",
    "# Evaluate Model2\n",
    "accuracy = evaluate_model(model2, val_dataloader, device)\n",
    "print(f\"Accuracy without fine-tuning: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1fbcd6-ed61-4b46-b168-e1af20f07871",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450dbbc0-6cff-4ad4-bff4-4fbdb10356ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to save the model and tokenizer\n",
    "save_directory = \"./fine_tuned_model\"\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved successfully in {save_directory}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566286e-b621-4c4d-a132-c47aa1456a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Directory where the model and tokenizer are saved\n",
    "save_directory = \"./fine_tuned_model\"\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(save_directory)\n",
    "tokenizer = BertTokenizer.from_pretrained(save_directory)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Fine-tuned model and tokenizer reloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c3457-3caa-49a0-9955-8d07c3e7675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Ensure your model is in evaluation mode and on the correct device\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Define SHAP prediction function\n",
    "def predict_fn(texts):\n",
    "    # Tokenize inputs (texts must be List[str])\n",
    "    tokens = tokenizer(\n",
    "        list(texts),  # Ensure the input is a List[str]\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    tokens = {key: val.to(device) for key, val in tokens.items()}\n",
    "    \n",
    "    # Get model logits and softmax probabilities\n",
    "    logits = model(**tokens).logits\n",
    "    return torch.nn.functional.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "# Select a subset of the validation dataset for SHAP analysis\n",
    "val_texts = dataset[\"validation\"][\"sentence\"][:10]  # First 10 sentences for analysis\n",
    "\n",
    "# Ensure `val_texts` is a List[str]\n",
    "assert isinstance(val_texts, list) and all(isinstance(t, str) for t in val_texts), \"val_texts must be a List[str]\"\n",
    "\n",
    "# Create SHAP explainer using PartitionExplainer\n",
    "explainer = shap.Explainer(predict_fn, tokenizer)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer(val_texts)\n",
    "\n",
    "# Check dimensions of SHAP values and adapt for visualization\n",
    "if hasattr(shap_values, \"values\"):\n",
    "    shap_values_array = shap_values.values\n",
    "    if shap_values_array.ndim == 2:\n",
    "        shap_values_array = shap_values_array[:, :, None]  # Add dummy dimension for outputs\n",
    "else:\n",
    "    raise ValueError(\"SHAP explainer did not generate expected values format.\")\n",
    "\n",
    "# Visualize SHAP values (take the first output class for binary classification)\n",
    "shap.summary_plot(shap_values_array[:, :, 1], val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1950f23-eb66-4778-be2d-c725aa870295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect SHAP values\n",
    "print(\"SHAP values object type:\", type(shap_values))\n",
    "if hasattr(shap_values, \"values\"):\n",
    "    print(\"SHAP values shape:\", getattr(shap_values.values, \"shape\", \"No shape attribute\"))\n",
    "else:\n",
    "    print(\"SHAP values do not have 'values' attribute.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0dedbb-e2ae-42b2-b3af-dbc179cb88e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract attention weights from the model\n",
    "def extract_attention_weights(model, inputs):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        attention_weights = outputs.attentions  # Tuple of attention maps (num_layers, batch_size, num_heads, seq_len, seq_len)\n",
    "    return attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9756433-5d47-48da-9012-06514e730f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained paraphrasing model (T5 small)\n",
    "paraphraser = pipeline(\"text2text-generation\", model=\"t5-small\", tokenizer=\"t5-small\", device=0)  # Use GPU if available\n",
    "\n",
    "# Function to replace words with synonyms\n",
    "def synonym_replacement(sentence):\n",
    "    synonyms = {\n",
    "        \"great\": [\"excellent\", \"fantastic\", \"wonderful\"],\n",
    "        \"terrible\": [\"horrible\", \"dreadful\", \"awful\"],\n",
    "        \"amazing\": [\"incredible\", \"phenomenal\", \"astonishing\"],\n",
    "        \"awful\": [\"bad\", \"terrible\", \"dreadful\"],\n",
    "    }\n",
    "    words = sentence.split()\n",
    "    for i, word in enumerate(words):\n",
    "        if word in synonyms:\n",
    "            words[i] = random.choice(synonyms[word])\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Function to delete random words\n",
    "def word_deletion(sentence):\n",
    "    words = sentence.split()\n",
    "    if len(words) > 1:\n",
    "        del words[random.randint(0, len(words) - 1)]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Function to swap adjacent words\n",
    "def word_swapping(sentence):\n",
    "    words = sentence.split()\n",
    "    if len(words) > 1:\n",
    "        idx = random.randint(0, len(words) - 2)\n",
    "        words[idx], words[idx + 1] = words[idx + 1], words[idx]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Function to introduce typos\n",
    "def introduce_typos(sentence):\n",
    "    words = list(sentence)\n",
    "    if len(words) > 0:\n",
    "        idx = random.randint(0, len(words) - 1)\n",
    "        typo_choice = random.choice([\"duplicate\", \"missing\"])\n",
    "        if typo_choice == \"duplicate\":\n",
    "            words.insert(idx, words[idx])  # Duplicate a character\n",
    "        elif typo_choice == \"missing\":\n",
    "            del words[idx]  # Remove a character\n",
    "    return \"\".join(words)\n",
    "\n",
    "# Function to reorder phrases\n",
    "def reorder_phrases(sentence):\n",
    "    words = sentence.split(\",\")\n",
    "    random.shuffle(words)\n",
    "    return \",\".join(words)\n",
    "\n",
    "# Function to add noise (punctuation variations)\n",
    "def add_noise(sentence):\n",
    "    words = sentence.split()\n",
    "    if len(words) > 1:\n",
    "        idx = random.randint(0, len(words) - 1)\n",
    "        words[idx] = words[idx] + random.choice([\".\", \",\", \"!\", \"?\"])\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Function to generate robust perturbations\n",
    "def robust_perturbation_final(sentence):\n",
    "    perturbed = []\n",
    "\n",
    "    # Lexical-level perturbations\n",
    "    perturbed.append(synonym_replacement(sentence))\n",
    "    perturbed.append(word_deletion(sentence))\n",
    "    perturbed.append(word_swapping(sentence))\n",
    "\n",
    "    # Noise injection\n",
    "    perturbed.append(introduce_typos(sentence))\n",
    "    perturbed.append(add_noise(sentence))\n",
    "\n",
    "    # Structural changes\n",
    "    reordered = reorder_phrases(sentence)\n",
    "    if reordered != sentence:\n",
    "        perturbed.append(reordered)\n",
    "\n",
    "    # Paraphrasing with language control\n",
    "    try:\n",
    "        paraphrased = paraphraser(sentence, max_length=128, num_return_sequences=1)\n",
    "        paraphrased_text = paraphrased[0]['generated_text']\n",
    "        if paraphrased_text.isascii():  # Ensure English output\n",
    "            perturbed.append(paraphrased_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Paraphrasing Error: {e}\")\n",
    "\n",
    "    # Contextual testing\n",
    "    if \"movie\" in sentence:\n",
    "        perturbed.append(sentence.replace(\"movie\", \"film\"))\n",
    "\n",
    "    # Filter meaningful, unique variations\n",
    "    perturbed = list(set(p for p in perturbed if p != sentence and len(p.strip()) > 0 and p.lower() != sentence.lower()))\n",
    "    return perturbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2be32c-a72b-4031-9ab2-575bd1052000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "sentence = \"The movie was amazing and well-directed.\"\n",
    "perturbations = robust_perturbation_final(sentence)\n",
    "print(\"Original:\", sentence)\n",
    "print(\"Perturbations:\", perturbations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10782f14-f950-46e7-a1d6-9dd4370692c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract attention weights\n",
    "def extract_attention_weights(model, tokenizer, sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_attentions=True)\n",
    "        attention_weights = outputs.attentions  # Tuple of attention maps (num_layers, batch_size, num_heads, seq_len, seq_len)\n",
    "    \n",
    "    return attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b583c-c347-4fc8-82ec-f58924b83078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "# Function to compute similarity between attention maps\n",
    "def compute_attention_similarity(att1, att2):\n",
    "    similarities = []\n",
    "    for layer in range(len(att1)):  # Iterate over layers\n",
    "        for head in range(att1[layer].shape[1]):  # Iterate over attention heads\n",
    "            for token_idx in range(att1[layer].shape[2]):  # Iterate over tokens\n",
    "                # Flatten attention scores for each token\n",
    "                original_att = att1[layer][0, head, token_idx].cpu().numpy()\n",
    "                perturbed_att = att2[layer][0, head, token_idx].cpu().numpy()\n",
    "                # Compute cosine similarity\n",
    "                score = 1 - cosine(original_att, perturbed_att)\n",
    "                similarities.append(score)\n",
    "    return np.mean(similarities)  # Average similarity across layers, heads, and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d23e6-aab2-4b5c-a039-a89281a04856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original sentence\n",
    "original_sentence = \"The movie was amazing and well-directed.\"\n",
    "\n",
    "# Generate dynamic perturbations\n",
    "perturbations = robust_perturbation_final(original_sentence)\n",
    "print(f\"Original Sentence: {original_sentence}\")\n",
    "print(f\"Generated Perturbations: {perturbations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c0680-1acf-4b2d-9035-a5dc3894325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attention for the original sentence\n",
    "original_attention = extract_attention_weights(model, tokenizer, original_sentence)\n",
    "\n",
    "# Compare each perturbation\n",
    "sac_scores = []\n",
    "for perturbed_sentence in perturbations:\n",
    "    perturbed_attention = extract_attention_weights(model, tokenizer, perturbed_sentence)\n",
    "    score = compute_attention_similarity(original_attention, perturbed_attention)\n",
    "    sac_scores.append(score)\n",
    "    print(f\"Perturbed Sentence: {perturbed_sentence} | SAC Score: {score:.4f}\")\n",
    "\n",
    "# Final SAC score (average across all perturbations)\n",
    "final_sac_score = np.mean(sac_scores)\n",
    "print(f\"Final SAC Score: {final_sac_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736cb6f1-608c-4089-b7c9-2436807f5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract attention maps layer-wise\n",
    "def extract_layer_attention_weights(model, tokenizer, sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_attentions=True)\n",
    "        attention_weights = outputs.attentions  # Tuple of (num_layers, batch_size, num_heads, seq_len, seq_len)\n",
    "    \n",
    "    return attention_weights  # List of attention maps for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d604586-fbce-421e-88ed-cf9a19905620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute layer-wise similarity\n",
    "def compute_layer_wise_similarity(att1, att2):\n",
    "    layer_similarities = []\n",
    "    \n",
    "    for layer in range(len(att1)):  # Iterate over layers\n",
    "        layer_scores = []\n",
    "        for head in range(att1[layer].shape[1]):  # Iterate over attention heads\n",
    "            for token_idx in range(att1[layer].shape[2]):  # Iterate over tokens\n",
    "                # Flatten attention scores for each token\n",
    "                original_att = att1[layer][0, head, token_idx].cpu().numpy()\n",
    "                perturbed_att = att2[layer][0, head, token_idx].cpu().numpy()\n",
    "                # Compute cosine similarity\n",
    "                score = 1 - cosine(original_att, perturbed_att)\n",
    "                layer_scores.append(score)\n",
    "        \n",
    "        # Average similarity for this layer\n",
    "        layer_similarities.append(np.mean(layer_scores))\n",
    "    \n",
    "    return layer_similarities  # List of similarities for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f87e3f-17a0-46ca-afda-be8971b21e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original sentence\n",
    "original_sentence = \"The movie was amazing and well-directed.\"\n",
    "\n",
    "# Generate dynamic perturbations\n",
    "perturbations = robust_perturbation_final(original_sentence)\n",
    "\n",
    "# Extract attention for the original sentence\n",
    "original_attention = extract_layer_attention_weights(fine_tuned_model, tokenizer, original_sentence)\n",
    "\n",
    "# Initialize layer-wise scores\n",
    "layer_wise_sac = np.zeros(len(original_attention))  # One score per layer\n",
    "\n",
    "# Compare each perturbation\n",
    "for perturbed_sentence in perturbations:\n",
    "    perturbed_attention = extract_layer_attention_weights(model, tokenizer, perturbed_sentence)\n",
    "    layer_scores = compute_layer_wise_similarity(original_attention, perturbed_attention)\n",
    "    layer_wise_sac += np.array(layer_scores)\n",
    "\n",
    "# Average SAC score per layer across all perturbations\n",
    "layer_wise_sac /= len(perturbations)\n",
    "\n",
    "# Print Layer-Wise SAC Results\n",
    "for layer_idx, score in enumerate(layer_wise_sac):\n",
    "    print(f\"Layer {layer_idx + 1}: SAC Score = {score:.4f}\")\n",
    "\n",
    "# Optionally visualize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(layer_wise_sac) + 1), layer_wise_sac, marker='o')\n",
    "plt.title(\"Layer-Wise SAC Scores\")\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"SAC Score\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa1afc-bacc-46f2-837f-6f9938477a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentences to test\n",
    "sentences = [\n",
    "    \"This film was beautifully directed and emotionally engaging.\",\n",
    "    \"The plot was predictable and the acting was uninspired.\"\n",
    "]\n",
    "\n",
    "# Generate perturbations for each sentence\n",
    "sentence_perturbations = {sentence: robust_perturbation_final(sentence) for sentence in sentences}\n",
    "\n",
    "# Print perturbations for validation\n",
    "for sentence, perturbations in sentence_perturbations.items():\n",
    "    print(f\"Original Sentence: {sentence}\")\n",
    "    print(f\"Perturbations: {perturbations}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9f553-b03a-40c8-97cf-bc1411f4cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer-wise SAC analysis for multiple sentences\n",
    "all_layer_sac = {}\n",
    "\n",
    "for original_sentence, perturbations in sentence_perturbations.items():\n",
    "    print(f\"Analyzing sentence: {original_sentence}\")\n",
    "    \n",
    "    # Extract attention for the original sentence\n",
    "    original_attention = extract_layer_attention_weights(model, tokenizer, original_sentence)\n",
    "    \n",
    "    # Initialize layer-wise scores\n",
    "    layer_wise_sac = np.zeros(len(original_attention))  # One score per layer\n",
    "    \n",
    "    # Compare each perturbation\n",
    "    for perturbed_sentence in perturbations:\n",
    "        perturbed_attention = extract_layer_attention_weights(finetuned_model, tokenizer, perturbed_sentence)\n",
    "        layer_scores = compute_layer_wise_similarity(original_attention, perturbed_attention)\n",
    "        layer_wise_sac += np.array(layer_scores)\n",
    "    \n",
    "    # Average SAC score per layer across all perturbations\n",
    "    layer_wise_sac /= len(perturbations)\n",
    "    all_layer_sac[original_sentence] = layer_wise_sac\n",
    "\n",
    "# Print results\n",
    "for sentence, layer_sac in all_layer_sac.items():\n",
    "    print(f\"\\nSentence: {sentence}\")\n",
    "    for layer_idx, score in enumerate(layer_sac):\n",
    "        print(f\"Layer {layer_idx + 1}: SAC Score = {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe14c6-f541-4ca7-90fb-cf9bd653099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot SAC scores for each sentence\n",
    "plt.figure(figsize=(10, 6))\n",
    "for sentence, layer_sac in all_layer_sac.items():\n",
    "    plt.plot(range(1, len(layer_sac) + 1), layer_sac, marker='o', label=sentence[:50] + \"...\")\n",
    "\n",
    "plt.title(\"Layer-Wise SAC Scores Across Sentences\")\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"SAC Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe694eff-cfe5-4006-84c3-1457e5bea7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze specific layers\n",
    "def freeze_layers(model, layers_to_freeze):\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_number = None\n",
    "        if \"encoder.layer.\" in name:\n",
    "            # Extract layer number\n",
    "            layer_number = int(name.split(\"encoder.layer.\")[1].split(\".\")[0])\n",
    "        \n",
    "        # Freeze specified layers\n",
    "        if layer_number in layers_to_freeze:\n",
    "            param.requires_grad = False\n",
    "\n",
    "# Fine-tune Layers 4–9\n",
    "weak_layers = [0, 1, 2, 10, 11]  # Layers to freeze (1–3 and 10–12)\n",
    "freeze_layers(model, weak_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9ed63-307e-40b2-b101-49b5b21326c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "# Define optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = len(train_dataloader) * 3  # Assuming 3 epochs\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# Fine-tuning loop with tqdm progress bar\n",
    "model.train()\n",
    "for epoch in range(3):  # 3 epochs\n",
    "    # Create a progress bar for each epoch\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        if 'label' in batch:  # Rename 'label' to 'labels'\n",
    "            batch['labels'] = batch.pop('label')\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar with loss\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1} completed. Loss = {loss.item()}\")\n",
    "\n",
    "# Save the fine-tuned model as model3\n",
    "model.save_pretrained(\"./model3\")\n",
    "tokenizer.save_pretrained(\"./model3\")\n",
    "\n",
    "print(\"SAC-driven fine-tuned model saved successfully as model3!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0322ce8-3a48-4c5c-bdf1-9b93c9ff7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm  # Use tqdm.notebook for Jupyter environments\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "# Define optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = len(train_dataloader) * 3  # Assuming 3 epochs\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# Fine-tuning loop with tqdm\n",
    "model.train()\n",
    "for epoch in range(3):  # 3 epochs\n",
    "    print(f\"Starting Epoch {epoch + 1}\")\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\", dynamic_ncols=True)\n",
    "\n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        if 'label' in batch:\n",
    "            batch['labels'] = batch.pop('label')\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar with loss\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} completed. Loss = {loss.item()}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./model3\")\n",
    "tokenizer.save_pretrained(\"./model3\")\n",
    "\n",
    "print(\"SAC-driven fine-tuned model saved successfully as model3!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd88b1-9da2-4a65-aebe-94e3d58ecce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model3 for evaluation\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the fine-tuned model3\n",
    "model3 = BertForSequenceClassification.from_pretrained(\"./model3\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./model3\")\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model3.to(device)\n",
    "model3.eval()\n",
    "\n",
    "print(\"model3 loaded successfully for SAC evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb782a-8c99-47ef-9425-eb8b19469237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute SAC scores for model3\n",
    "all_layer_sac_model3 = {}\n",
    "\n",
    "for original_sentence, perturbations in sentence_perturbations.items():\n",
    "    print(f\"Analyzing sentence: {original_sentence} with model3\")\n",
    "    \n",
    "    # Extract attention for the original sentence\n",
    "    original_attention_model3 = extract_layer_attention_weights(model3, tokenizer, original_sentence)\n",
    "    \n",
    "    # Initialize layer-wise SAC scores\n",
    "    layer_wise_sac_model3 = np.zeros(len(original_attention_model3))  # One score per layer\n",
    "\n",
    "    # Compare each perturbation\n",
    "    for perturbed_sentence in perturbations:\n",
    "        perturbed_attention_model3 = extract_layer_attention_weights(model3, tokenizer, perturbed_sentence)\n",
    "        layer_scores_model3 = compute_layer_wise_similarity(original_attention_model3, perturbed_attention_model3)\n",
    "        layer_wise_sac_model3 += np.array(layer_scores_model3)\n",
    "    \n",
    "    # Average SAC score per layer across all perturbations\n",
    "    layer_wise_sac_model3 /= len(perturbations)\n",
    "    all_layer_sac_model3[original_sentence] = layer_wise_sac_model3\n",
    "\n",
    "# Print results\n",
    "for sentence, layer_sac in all_layer_sac_model3.items():\n",
    "    print(f\"\\nSentence: {sentence}\")\n",
    "    for layer_idx, score in enumerate(layer_sac):\n",
    "        print(f\"Layer {layer_idx + 1}: SAC Score = {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f25b741-e8b5-48bc-95c9-4d4556907231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot SAC scores for each sentence (before and after fine-tuning)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for sentence, sac_original in all_layer_sac.items():\n",
    "    sac_model3 = all_layer_sac_model3[sentence]\n",
    "    plt.plot(range(1, len(sac_original) + 1), sac_original, marker='o', label=f\"Original {sentence[:50]}...\")\n",
    "    plt.plot(range(1, len(sac_model3) + 1), sac_model3, marker='x', label=f\"Model3 {sentence[:50]}...\")\n",
    "\n",
    "plt.title(\"Layer-Wise SAC Scores (Original vs Fine-Tuned)\")\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"SAC Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4fecaf-559d-45de-98ba-8a003ee7780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "\n",
    "# Load model3's configuration\n",
    "config = BertConfig.from_pretrained(\"./model3\")\n",
    "config.hidden_dropout_prob = 0.1  # Increase dropout for better regularization\n",
    "config.attention_probs_dropout_prob = 0.1\n",
    "\n",
    "# Load the model with modified dropout\n",
    "model3_with_dropout = BertForSequenceClassification.from_pretrained(\"./model3\", config=config)\n",
    "model3_with_dropout.to(device)\n",
    "\n",
    "model3.save_pretrained(f\"./model3_variant_dropout\")\n",
    "tokenizer.save_pretrained(f\"./model3_variant_dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d45b4f1-b82f-4fa1-8a93-0c4bf66b3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Directory where the model3_variant_dropout is saved\n",
    "variant_path = \"./model3_variant_dropout\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model3_variant_dropout = BertForSequenceClassification.from_pretrained(variant_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(variant_path)\n",
    "\n",
    "# Move the model to the appropriate device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model3_variant_dropout.to(device)\n",
    "model3_variant_dropout.eval()\n",
    "\n",
    "print(\"model3_variant_dropout loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289c385-cc37-4c6f-8a41-702a74b7d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for original_sentence, perturbations in sentence_perturbations.items():\n",
    "    print(f\"Analyzing sentence: {original_sentence} with model3_variant_dropout\")\n",
    "    \n",
    "    # Extract attention weights for the original sentence\n",
    "    original_attention = extract_layer_attention_weights(model3_variant_dropout, tokenizer, original_sentence)\n",
    "\n",
    "    layer_wise_sac = np.zeros(len(original_attention))  # Initialize SAC scores for each layer\n",
    "    \n",
    "    # Compare each perturbation\n",
    "    for perturbed_sentence in perturbations:\n",
    "        perturbed_attention = extract_layer_attention_weights(model3_variant_dropout, tokenizer, perturbed_sentence)\n",
    "        layer_scores = compute_layer_wise_similarity(original_attention, perturbed_attention)\n",
    "        layer_wise_sac += np.array(layer_scores)\n",
    "    \n",
    "    # Average SAC scores across all perturbations\n",
    "    layer_wise_sac /= len(perturbations)\n",
    "    print(f\"Layer-wise SAC scores for model3_variant_dropout: {layer_wise_sac}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361fd1de-5510-4620-8fa8-211ed6946e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot SAC scores for each sentence (before and after fine-tuning)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for sentence, sac_original in all_layer_sac.items():\n",
    "    sac_model3 = all_layer_sac_model3[sentence]\n",
    "    plt.plot(range(1, len(sac_original) + 1), sac_original, marker='o', label=f\"Original {sentence[:50]}...\")\n",
    "    plt.plot(range(1, len(sac_model3) + 1), sac_model3, marker='x', label=f\"Model3 {sentence[:50]}...\")\n",
    "\n",
    "plt.title(\"Layer-Wise SAC Scores (Original vs Fine-Tuned)\")\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"SAC Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a04ea-5a68-4678-a18b-3b3205cf08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertLayer\n",
    "\n",
    "class CustomBertLayer(BertLayer):\n",
    "    def forward(self, hidden_states, *args, **kwargs):\n",
    "        layer_output = super().forward(hidden_states, *args, **kwargs)\n",
    "        if self.layer_index in range(4, 10):  # Mid-layers\n",
    "            layer_output = torch.nn.functional.relu(layer_output)\n",
    "        return layer_output\n",
    "\n",
    "# Replace the mid-layers in model3\n",
    "for idx in range(4, 10):\n",
    "    model3.bert.encoder.layer[idx] = CustomBertLayer(model3.bert.encoder.layer[idx])\n",
    "\n",
    "model3.save_pretrained(f\"./model3_variant_relu\")\n",
    "tokenizer.save_pretrained(f\"./model3_variant_relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a452ea-8c45-422e-8491-0e3e96ecec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Load the fine-tuned model3 and tokenizer\n",
    "model3 = BertForSequenceClassification.from_pretrained(\"./model3\", output_attentions=True, output_hidden_states=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./model3\")\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model3.to(device)\n",
    "\n",
    "class EnhancedBertModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(EnhancedBertModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.task_head = nn.Linear(base_model.config.hidden_size, 2)  # Assuming binary classification\n",
    "\n",
    "        # Learnable scaling factors for mid-layers (Layers 4–9)\n",
    "        self.scaling_factors = nn.Parameter(torch.ones(6))  # For Layers 4–9\n",
    "        \n",
    "        # Auxiliary head for intermediate supervision\n",
    "        self.auxiliary_head = nn.Linear(base_model.config.hidden_size, 2)\n",
    "\n",
    "        # Regularization weight for layer-wise attention\n",
    "        self.attention_reg_weight = 0.1\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, auxiliary_labels=None):\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=True,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        hidden_states = outputs.hidden_states\n",
    "        attentions = outputs.attentions\n",
    "\n",
    "        # Enhanced residuals: Add attention residuals for mid-layers\n",
    "        mid_layer_outputs = []\n",
    "        for i, hidden_state in enumerate(hidden_states[4:10]):  # Layers 4–9\n",
    "            scaled_hidden = self.scaling_factors[i] * hidden_state\n",
    "            residual_output = scaled_hidden + hidden_states[3 + i]  # Enhanced residual\n",
    "            mid_layer_outputs.append(residual_output)\n",
    "\n",
    "        # Use the [CLS] token representation for classification\n",
    "        cls_representation = hidden_states[-1][:, 0, :]  # [CLS] token is at index 0\n",
    "        task_output = self.task_head(self.dropout(cls_representation))\n",
    "\n",
    "        # Auxiliary supervision loss (if labels provided)\n",
    "        aux_loss = None\n",
    "        if auxiliary_labels is not None:\n",
    "            aux_output = self.auxiliary_head(cls_representation)\n",
    "            aux_loss = nn.CrossEntropyLoss()(aux_output, auxiliary_labels)\n",
    "\n",
    "        return task_output, aux_loss, attentions, mid_layer_outputs\n",
    "\n",
    "\n",
    "    def compute_attention_regularization(self, attentions):\n",
    "        \"\"\"\n",
    "        Apply layer-wise attention regularization to minimize divergence\n",
    "        between adjacent layers in mid-layer attentions.\n",
    "        \"\"\"\n",
    "        reg_loss = 0.0\n",
    "        for i in range(4, 9):  # Layers 4 to 9\n",
    "            reg_loss += torch.mean((attentions[i] - attentions[i + 1]) ** 2)  # L2 regularization\n",
    "        return self.attention_reg_weight * reg_loss\n",
    "\n",
    "# Enhance model3 with the new architecture\n",
    "enhanced_model3 = EnhancedBertModel(model3)\n",
    "enhanced_model3.to(device)\n",
    "\n",
    "# Helper functions\n",
    "def extract_layer_attention_weights(model, tokenizer, sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs[2]  # Return attention weights (index 2 in the tuple)\n",
    "\n",
    "def compute_layer_wise_similarity(original_attention, perturbed_attention):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity for attention maps between original and perturbed inputs,\n",
    "    aligning their shapes if necessary.\n",
    "    \"\"\"\n",
    "    layer_scores = []\n",
    "    for orig, pert in zip(original_attention, perturbed_attention):\n",
    "        # Convert to numpy arrays\n",
    "        orig = orig.squeeze().detach().cpu().numpy()\n",
    "        pert = pert.squeeze().detach().cpu().numpy()\n",
    "\n",
    "        # Align shapes (truncate or pad to match dimensions)\n",
    "        min_len = min(orig.shape[1], pert.shape[1])\n",
    "        orig = orig[:, :min_len, :min_len]  # Truncate to min sequence length\n",
    "        pert = pert[:, :min_len, :min_len]  # Truncate to min sequence length\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        sim = np.dot(orig.flatten(), pert.flatten()) / (\n",
    "            np.linalg.norm(orig.flatten()) * np.linalg.norm(pert.flatten()) + 1e-8\n",
    "        )\n",
    "        layer_scores.append(sim)\n",
    "    return layer_scores\n",
    "\n",
    "# Evaluate SAC scores\n",
    "sentence_perturbations = {\n",
    "    \"The cat is on the mat.\": [\"The cat is over the mat.\", \"The cat's on the mat!\", \"The mat is under the cat.\"],\n",
    "    # Add more sentence-perturbation pairs as needed\n",
    "}\n",
    "\n",
    "print(\"Evaluating SAC scores with Enhanced Model...\")\n",
    "enhanced_model3.eval()\n",
    "\n",
    "for original_sentence, perturbations in sentence_perturbations.items():\n",
    "    print(f\"Analyzing sentence: {original_sentence}\")\n",
    "    \n",
    "    # Extract attention weights for the original sentence\n",
    "    original_attention = extract_layer_attention_weights(enhanced_model3, tokenizer, original_sentence)\n",
    "    \n",
    "    layer_wise_sac = np.zeros(len(original_attention))  # Initialize SAC scores for each layer\n",
    "    \n",
    "    # Compare each perturbation\n",
    "    for perturbed_sentence in perturbations:\n",
    "        perturbed_attention = extract_layer_attention_weights(enhanced_model3, tokenizer, perturbed_sentence)\n",
    "        layer_scores = compute_layer_wise_similarity(original_attention, perturbed_attention)\n",
    "        layer_wise_sac += np.array(layer_scores)\n",
    "    \n",
    "    # Average SAC scores across all perturbations\n",
    "    layer_wise_sac /= len(perturbations)\n",
    "    print(f\"Layer-wise SAC scores for Enhanced Model: {layer_wise_sac}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d38b10-51ec-44d6-b9bb-fecdaac05fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference loop for accuracy evaluation\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "enhanced_model3.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        # Move data to the appropriate device (GPU or CPU)\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Rename 'label' to 'labels' if necessary\n",
    "        if \"label\" in batch:\n",
    "            batch[\"labels\"] = batch.pop(\"label\")\n",
    "        \n",
    "        # Forward pass\n",
    "        task_output, _, _, _ = model3(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            token_type_ids=batch.get(\"token_type_ids\", None),  # Handle token_type_ids if present\n",
    "        )\n",
    "        \n",
    "        # Get predictions from logits\n",
    "        predictions = torch.argmax(task_output, dim=-1)\n",
    "        \n",
    "        # Update accuracy metrics\n",
    "        correct += (predictions == batch[\"labels\"]).sum().item()\n",
    "        total += batch[\"labels\"].size(0)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a084aa36-b1f5-453b-9f8b-c0760f837c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Load the fine-tuned model3 and tokenizer\n",
    "model3 = BertForSequenceClassification.from_pretrained(\"./model3\", output_attentions=True, output_hidden_states=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./model3\")\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model3.to(device)\n",
    "\n",
    "class EnhancedBertModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(EnhancedBertModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.task_head = nn.Linear(base_model.config.hidden_size, 2)  # Assuming binary classification\n",
    "\n",
    "        # Cross-layer attention weights for dynamic interaction\n",
    "        self.cross_layer_weights = nn.Parameter(torch.tensor([0.33, 0.33, 0.33]))  # Equal weights initially\n",
    "        \n",
    "        # Learnable scaling factors for mid-layers (Layers 4–9)\n",
    "        self.scaling_factors = nn.Parameter(torch.ones(6))  # For Layers 4–9\n",
    "\n",
    "        # Regularization weight for layer-wise attention\n",
    "        self.regularization_weight = 0.05  # Lower starting regularization weight\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=True,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        hidden_states = outputs.hidden_states\n",
    "        attentions = outputs.attentions\n",
    "\n",
    "        # Cross-layer dynamic interaction\n",
    "        lower_output = hidden_states[3]  # Lower layers\n",
    "        mid_output = torch.mean(torch.stack(hidden_states[4:10]), dim=0)  # Mid-layers\n",
    "        upper_output = hidden_states[-1]  # Upper layers\n",
    "        cross_output = (\n",
    "            self.cross_layer_weights[0] * lower_output +\n",
    "            self.cross_layer_weights[1] * mid_output +\n",
    "            self.cross_layer_weights[2] * upper_output\n",
    "        )\n",
    "\n",
    "        # Use the [CLS] token representation for classification\n",
    "        cls_representation = cross_output[:, 0, :]  # [CLS] token at index 0\n",
    "        task_output = self.task_head(self.dropout(cls_representation))\n",
    "\n",
    "        return task_output, attentions, hidden_states\n",
    "\n",
    "    def compute_attention_regularization(self, attentions):\n",
    "        \"\"\"\n",
    "        Apply layer-wise attention regularization to minimize divergence\n",
    "        between specific mid-layer attention maps.\n",
    "        \"\"\"\n",
    "        reg_loss = 0.0\n",
    "        for i in range(5, 8):  # Apply regularization only to Layers 6–8\n",
    "            reg_loss += torch.mean((attentions[i] - attentions[i + 1]) ** 2)  # L2 regularization\n",
    "        return self.regularization_weight * reg_loss\n",
    "\n",
    "# Enhance model3 with the new architecture\n",
    "enhanced_model3 = EnhancedBertModel(model3)\n",
    "enhanced_model3.to(device)\n",
    "\n",
    "# Helper functions\n",
    "def extract_layer_attention_weights(model, tokenizer, sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs[1]  # Return attention weights (index 1 in the tuple)\n",
    "\n",
    "def compute_layer_wise_similarity(original_attention, perturbed_attention):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity for attention maps between original and perturbed inputs,\n",
    "    aligning their shapes if necessary.\n",
    "    \"\"\"\n",
    "    layer_scores = []\n",
    "    for orig, pert in zip(original_attention, perturbed_attention):\n",
    "        # Convert to numpy arrays\n",
    "        orig = orig.squeeze().detach().cpu().numpy()\n",
    "        pert = pert.squeeze().detach().cpu().numpy()\n",
    "\n",
    "        # Align shapes (truncate or pad to match dimensions)\n",
    "        min_len = min(orig.shape[1], pert.shape[1])\n",
    "        orig = orig[:, :min_len, :min_len]  # Truncate to min sequence length\n",
    "        pert = pert[:, :min_len, :min_len]  # Truncate to min sequence length\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        sim = np.dot(orig.flatten(), pert.flatten()) / (\n",
    "            np.linalg.norm(orig.flatten()) * np.linalg.norm(pert.flatten()) + 1e-8\n",
    "        )\n",
    "        layer_scores.append(sim)\n",
    "    return layer_scores\n",
    "\n",
    "# Evaluate SAC scores\n",
    "sentence_perturbations = {\n",
    "    \"The cat is on the mat.\": [\"The cat is over the mat.\", \"The cat's on the mat!\", \"The mat is under the cat.\"],\n",
    "    # Add more sentence-perturbation pairs as needed\n",
    "}\n",
    "\n",
    "print(\"Evaluating SAC scores with Enhanced Model...\")\n",
    "enhanced_model3.eval()\n",
    "\n",
    "for original_sentence, perturbations in sentence_perturbations.items():\n",
    "    print(f\"Analyzing sentence: {original_sentence}\")\n",
    "    \n",
    "    # Extract attention weights for the original sentence\n",
    "    original_attention = extract_layer_attention_weights(enhanced_model3, tokenizer, original_sentence)\n",
    "    \n",
    "    layer_wise_sac = np.zeros(len(original_attention))  # Initialize SAC scores for each layer\n",
    "    \n",
    "    # Compare each perturbation\n",
    "    for perturbed_sentence in perturbations:\n",
    "        perturbed_attention = extract_layer_attention_weights(enhanced_model3, tokenizer, perturbed_sentence)\n",
    "        layer_scores = compute_layer_wise_similarity(original_attention, perturbed_attention)\n",
    "        layer_wise_sac += np.array(layer_scores)\n",
    "    \n",
    "    # Average SAC scores across all perturbations\n",
    "    layer_wise_sac /= len(perturbations)\n",
    "    print(f\"Layer-wise SAC scores for Enhanced Model: {layer_wise_sac}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba0542-b7c4-4b0a-a467-d7153d0c9d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load model3 and tokenizer\n",
    "model3 = BertForSequenceClassification.from_pretrained(\"./model3\", output_attentions=True, output_hidden_states=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./model3\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Enhanced2BertModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(Enhanced2BertModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.task_head = nn.Linear(base_model.config.hidden_size, 2)  # Task-specific head\n",
    "        self.auxiliary_head = nn.Linear(base_model.config.hidden_size, 2)  # Auxiliary head\n",
    "\n",
    "        # Cross-layer attention weights for dynamic interaction\n",
    "        self.cross_layer_weights = nn.Parameter(torch.tensor([0.2, 0.6, 0.2]))  # Prioritize mid-layers\n",
    "        self.scaling_factors = nn.Parameter(torch.ones(6))  # Learnable scaling factors for mid-layers\n",
    "        self.regularization_weight = 0.01  # Starting regularization weight\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, auxiliary_labels=None):\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=True,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        hidden_states = outputs.hidden_states\n",
    "        attentions = outputs.attentions\n",
    "\n",
    "        # Cross-layer dynamic interaction\n",
    "        lower_output = hidden_states[3]  # Lower layers\n",
    "        mid_output = torch.mean(torch.stack(hidden_states[4:10]), dim=0)  # Mid-layers\n",
    "        upper_output = hidden_states[-1]  # Upper layers\n",
    "        cross_output = (\n",
    "            self.cross_layer_weights[0] * lower_output +\n",
    "            self.cross_layer_weights[1] * mid_output +\n",
    "            self.cross_layer_weights[2] * upper_output\n",
    "        )\n",
    "\n",
    "        # Apply dropout to cross-layer outputs\n",
    "        cross_output = self.dropout(cross_output)\n",
    "\n",
    "        # Use the [CLS] token for classification\n",
    "        cls_representation = cross_output[:, 0, :]\n",
    "        task_output = self.task_head(cls_representation)\n",
    "\n",
    "        # Auxiliary supervision\n",
    "        aux_loss = None\n",
    "        if auxiliary_labels is not None:\n",
    "            aux_output = self.auxiliary_head(cls_representation)\n",
    "            aux_loss = nn.CrossEntropyLoss()(aux_output, auxiliary_labels)\n",
    "\n",
    "        return task_output, aux_loss, attentions, hidden_states\n",
    "\n",
    "    def compute_attention_regularization(self, attentions):\n",
    "        # Regularize mid-layer attention transitions (Layers 6–8)\n",
    "        reg_loss = 0.0\n",
    "        for i in range(5, 8):\n",
    "            reg_loss += torch.mean((attentions[i] - attentions[i + 1]) ** 2)\n",
    "        return self.regularization_weight * reg_loss\n",
    "\n",
    "# Instantiate the enhanced model\n",
    "enhanced2_model3 = Enhanced2BertModel(model3)\n",
    "enhanced2_model3.to(device)\n",
    "\n",
    "# Optimizer with layer-specific learning rates\n",
    "# Optimizer with layer-specific learning rates\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": enhanced2_model3.base_model.bert.encoder.layer[:4].parameters(), \"lr\": 1e-5},  # Lower layers\n",
    "    {\"params\": enhanced2_model3.base_model.bert.encoder.layer[4:10].parameters(), \"lr\": 2e-5},  # Mid-layers\n",
    "    {\"params\": enhanced2_model3.base_model.bert.encoder.layer[10:].parameters(), \"lr\": 1e-5},  # Upper layers\n",
    "    {\"params\": enhanced2_model3.task_head.parameters(), \"lr\": 2e-5},  # Task-specific head\n",
    "    {\"params\": enhanced2_model3.auxiliary_head.parameters(), \"lr\": 2e-5},  # Auxiliary head\n",
    "])\n",
    "\n",
    "# Training Loop\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Training Loop with Progress Bar\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    enhanced2_model3.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for batch in train_progress_bar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        if \"label\" in batch:\n",
    "            batch[\"labels\"] = batch.pop(\"label\")\n",
    "\n",
    "        # Forward pass\n",
    "        task_output, aux_loss, attentions, _ = enhanced2_model3(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            token_type_ids=batch.get(\"token_type_ids\", None),\n",
    "            auxiliary_labels=batch.get(\"auxiliary_labels\", None)\n",
    "        )\n",
    "\n",
    "        # Compute losses\n",
    "        task_loss = nn.CrossEntropyLoss()(task_output, batch[\"labels\"])\n",
    "        reg_loss = enhanced2_model3.compute_attention_regularization(attentions)\n",
    "        loss = task_loss + reg_loss + (aux_loss if aux_loss is not None else 0)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        train_progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Training Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # Validation Loop with Progress Bar\n",
    "    enhanced2_model3.eval()\n",
    "    correct, total = 0, 0\n",
    "    val_progress_bar = tqdm(val_dataloader, desc=\"Validating\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_progress_bar:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            if \"label\" in batch:\n",
    "                batch[\"labels\"] = batch.pop(\"label\")\n",
    "\n",
    "            # Forward pass\n",
    "            task_output, _, attentions, _ = enhanced2_model3(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                token_type_ids=batch.get(\"token_type_ids\", None)\n",
    "            )\n",
    "\n",
    "            # Predictions\n",
    "            predictions = torch.argmax(task_output, dim=-1)\n",
    "            correct += (predictions == batch[\"labels\"]).sum().item()\n",
    "            total += batch[\"labels\"].size(0)\n",
    "\n",
    "            # Update progress bar with running accuracy\n",
    "            val_progress_bar.set_postfix(accuracy=(correct / total) * 100)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch + 1}, Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ce78a-3fb2-4115-981e-43d7a0001df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import mse_loss\n",
    "\n",
    "def compute_sac_scores(model, dataloader, tokenizer, device):\n",
    "    model.eval()\n",
    "    sac_scores = {layer: [] for layer in range(12)}  # Assuming 12 layers in BERT\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Prepare inputs\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "            # Generate perturbed inputs (example: adding noise)\n",
    "            perturbed_ids = input_ids.clone()  # Clone and perturb\n",
    "            perturbed_ids[:, 1] = tokenizer.convert_tokens_to_ids(\"[MASK]\")  # Example perturbation\n",
    "\n",
    "            # Get attentions for original and perturbed inputs\n",
    "            _, _, original_attentions, _ = model(input_ids, attention_mask)\n",
    "            _, _, perturbed_attentions, _ = model(perturbed_ids, attention_mask)\n",
    "\n",
    "            # Compute SAC for each layer\n",
    "            for layer in range(len(original_attentions)):\n",
    "                original = original_attentions[layer]\n",
    "                perturbed = perturbed_attentions[layer]\n",
    "                sac_score = mse_loss(original, perturbed).item()\n",
    "                sac_scores[layer].append(sac_score)\n",
    "\n",
    "    # Aggregate SAC scores per layer\n",
    "    avg_sac_scores = {layer: np.mean(scores) for layer, scores in sac_scores.items()}\n",
    "    return avg_sac_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537c8b9-aa80-4305-b1af-6b5b58d91053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            if \"label\" in batch:\n",
    "                batch[\"labels\"] = batch.pop(\"label\")\n",
    "\n",
    "            # Forward pass\n",
    "            task_output, _, _, _ = model(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                token_type_ids=batch.get(\"token_type_ids\", None)\n",
    "            )\n",
    "\n",
    "            # Predictions\n",
    "            predictions = torch.argmax(task_output, dim=-1)\n",
    "            correct += (predictions == batch[\"labels\"]).sum().item()\n",
    "            total += batch[\"labels\"].size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c53a2-adf9-4cc2-a340-f06171293273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "def analyze_sentence(model, tokenizer, sentence, perturbed_sentence, device, max_length=128):\n",
    "    # Tokenize and encode both sentences with a fixed max_length\n",
    "    encoded_orig = tokenizer(sentence, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_length).to(device)\n",
    "    encoded_pert = tokenizer(perturbed_sentence, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_length).to(device)\n",
    "\n",
    "    # Enable attentions and hidden states\n",
    "    model.config.output_attentions = True\n",
    "    model.config.output_hidden_states = True\n",
    "\n",
    "    # Get attention weights for both\n",
    "    with torch.no_grad():\n",
    "        original_output = model(**encoded_orig)\n",
    "        perturbed_output = model(**encoded_pert)\n",
    "\n",
    "        # Extract attentions\n",
    "        original_attentions = original_output.attentions\n",
    "        perturbed_attentions = perturbed_output.attentions\n",
    "\n",
    "    # Compute SAC scores layer-wise\n",
    "    sac_scores = []\n",
    "    for layer in range(len(original_attentions)):\n",
    "        original = original_attentions[layer].squeeze(0)  # Shape: (num_heads, seq_len, seq_len)\n",
    "        perturbed = perturbed_attentions[layer].squeeze(0)\n",
    "\n",
    "        # Align sizes if necessary\n",
    "        min_seq_len = min(original.shape[-1], perturbed.shape[-1])\n",
    "        original = original[:, :min_seq_len, :min_seq_len]\n",
    "        perturbed = perturbed[:, :min_seq_len, :min_seq_len]\n",
    "\n",
    "        # Flatten and compute cosine similarity\n",
    "        original_flat = original.view(-1)\n",
    "        perturbed_flat = perturbed.view(-1)\n",
    "        sac_score = cosine_similarity(original_flat, perturbed_flat, dim=0).item()\n",
    "\n",
    "        sac_scores.append(sac_score)\n",
    "\n",
    "    # Print formatted results\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    for layer, score in enumerate(sac_scores, start=1):\n",
    "        print(f\"Layer {layer}: SAC Score = {score:.4f}\")\n",
    "\n",
    "    return sac_scores\n",
    "# Example usage\n",
    "model = BertForSequenceClassification.from_pretrained(\"./model3\", output_attentions=True, output_hidden_states=True).to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./model3\")\n",
    "\n",
    "sentence_1 = \"This film was beautifully directed and emotionally engaging.\"\n",
    "perturbed_sentence_1 = \"This movie was beautifully directed and emotionally touching.\"\n",
    "\n",
    "sentence_2 = \"The plot was predictable and the acting was uninspired.\"\n",
    "perturbed_sentence_2 = \"The storyline was obvious and the performance was dull.\"\n",
    "\n",
    "# Analyze both sentences\n",
    "analyze_sentence(model, tokenizer, sentence_1, perturbed_sentence_1, device)\n",
    "analyze_sentence(model, tokenizer, sentence_2, perturbed_sentence_2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9eac4-a9f3-4451-be3d-90a39a494bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Reload the fine-tuned model and tokenizer with updated configuration\n",
    "fine_tuned_model = BertForSequenceClassification.from_pretrained(\n",
    "    \"./fine_tuned_model\",\n",
    "    output_attentions=True,  # Ensure attentions are returned\n",
    "    output_hidden_states=True\n",
    ")\n",
    "fine_tuned_tokenizer = BertTokenizer.from_pretrained(\"./fine_tuned_model\")\n",
    "fine_tuned_model.to(device)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "fine_tuned_model.to(device)\n",
    "enhanced2_model3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f2fa1-a13c-4554-a142-e20efe9b01ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, tokenizer, dataloader, device, is_enhanced=False):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            labels = batch.pop(\"label\")  # Extract labels\n",
    "\n",
    "            if is_enhanced:\n",
    "                # For Enhanced2BertModel: Use outputs without 'labels'\n",
    "                task_output, _, _, _ = model(**batch)\n",
    "                logits = task_output\n",
    "            else:\n",
    "                # For BertForSequenceClassification: Use outputs with 'labels'\n",
    "                outputs = model(**batch)\n",
    "                logits = outputs.logits\n",
    "\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # Compute accuracy\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b0cac4-dfb1-439f-840f-deea35fb67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "def compute_sac_scores(model, tokenizer, sentences, perturbed_sentences, device, is_enhanced=False):\n",
    "    model.eval()\n",
    "    sac_scores = {layer: [] for layer in range(12)}  # Assuming 12 layers in BERT\n",
    "\n",
    "    for orig_sent, pert_sent in zip(sentences, perturbed_sentences):\n",
    "        # Tokenize sentences\n",
    "        orig_inputs = tokenizer(orig_sent, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        pert_inputs = tokenizer(pert_sent, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            if is_enhanced:\n",
    "                orig_outputs = model(**orig_inputs)\n",
    "                pert_outputs = model(**pert_inputs)\n",
    "                orig_attentions = orig_outputs[2]  # Extract attentions (third item in tuple)\n",
    "                pert_attentions = pert_outputs[2]\n",
    "            else:\n",
    "                orig_outputs = model(**orig_inputs)\n",
    "                pert_outputs = model(**pert_inputs)\n",
    "                orig_attentions = orig_outputs.attentions\n",
    "                pert_attentions = pert_outputs.attentions\n",
    "\n",
    "            if orig_attentions is None or pert_attentions is None:\n",
    "                raise ValueError(\n",
    "                    \"Model did not return attention weights. Ensure `output_attentions=True` in the model configuration.\"\n",
    "                )\n",
    "\n",
    "        # Compute SAC score per layer\n",
    "        for layer in range(len(orig_attentions)):\n",
    "            orig_layer = orig_attentions[layer].squeeze(0)\n",
    "            pert_layer = pert_attentions[layer].squeeze(0)\n",
    "\n",
    "            # Flatten and calculate cosine similarity\n",
    "            orig_flat = orig_layer.view(-1)\n",
    "            pert_flat = pert_layer.view(-1)\n",
    "            sac_score = cosine_similarity(orig_flat, pert_flat, dim=0).item()\n",
    "            sac_scores[layer].append(sac_score)\n",
    "\n",
    "    # Average SAC scores per layer\n",
    "    avg_sac_scores = {layer: sum(scores) / len(scores) for layer, scores in sac_scores.items()}\n",
    "    return avg_sac_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf642ae-b757-4f2f-b5d0-610bd44b1350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perturbed_sentences(sentences):\n",
    "    def perturb(sentence):\n",
    "        synonym_dict = {\"film\": \"movie\", \"engaging\": \"captivating\", \"predictable\": \"obvious\"}\n",
    "        words = sentence.split()\n",
    "        perturbed = [synonym_dict.get(word, word) for word in words]\n",
    "        return \" \".join(perturbed)\n",
    "    \n",
    "    return [perturb(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5907ab-1d36-4fb2-8413-7e88b8aa44a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, max_length=128):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(sentence, padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "# Define your original dataset\n",
    "original_sentences = [\"This film was beautifully directed and emotionally engaging.\",\n",
    "                      \"The plot was predictable and the acting was uninspired.\"]\n",
    "original_labels = [1, 0]  # Replace with the actual labels for the sentences\n",
    "\n",
    "# Create DataLoader for the original dataset\n",
    "original_dataset = CustomDataset(original_sentences, original_labels, fine_tuned_tokenizer)\n",
    "original_dataloader = DataLoader(original_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9f0df-cf28-44fb-90a4-35bd29087c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate perturbed sentences\n",
    "perturbed_sentences = generate_perturbed_sentences(original_sentences)\n",
    "\n",
    "# Create DataLoader for the perturbed dataset\n",
    "perturbed_dataset = CustomDataset(perturbed_sentences, original_labels, fine_tuned_tokenizer)\n",
    "perturbed_dataloader = DataLoader(perturbed_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3635591a-87a2-4af0-8027-aa95ac246b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy\n",
    "# Fine-tuned model accuracy\n",
    "fine_tuned_acc_original = evaluate_accuracy(fine_tuned_model, fine_tuned_tokenizer, original_dataloader, device)\n",
    "fine_tuned_acc_perturbed = evaluate_accuracy(fine_tuned_model, fine_tuned_tokenizer, perturbed_dataloader, device)\n",
    "\n",
    "# Enhanced model accuracy\n",
    "enhanced_acc_original = evaluate_accuracy(enhanced2_model3, fine_tuned_tokenizer, original_dataloader, device, is_enhanced=True)\n",
    "enhanced_acc_perturbed = evaluate_accuracy(enhanced2_model3, fine_tuned_tokenizer, perturbed_dataloader, device, is_enhanced=True)\n",
    "\n",
    "# Compute SAC scores\n",
    "fine_tuned_sac = compute_sac_scores(fine_tuned_model, fine_tuned_tokenizer, original_sentences, perturbed_sentences, device)\n",
    "enhanced_sac = compute_sac_scores(enhanced2_model3, fine_tuned_tokenizer, original_sentences, perturbed_sentences, device)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Fine-Tuned Model: Original Accuracy = {fine_tuned_acc_original:.2f}, Perturbed Accuracy = {fine_tuned_acc_perturbed:.2f}\")\n",
    "print(f\"Enhanced Model: Original Accuracy = {enhanced_acc_original:.2f}, Perturbed Accuracy = {enhanced_acc_perturbed:.2f}\")\n",
    "print(\"\\nSAC Scores (Fine-Tuned Model):\", fine_tuned_sac)\n",
    "print(\"\\nSAC Scores (Enhanced Model):\", enhanced_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18717260-d892-4c91-ac04-d7cafc286028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test attention outputs\n",
    "test_sentence = \"This film was beautifully directed.\"\n",
    "inputs = fine_tuned_tokenizer(test_sentence, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = fine_tuned_model(**inputs)\n",
    "    if outputs.attentions is None:\n",
    "        raise ValueError(\"Attention weights are still not being returned. Check the model configuration.\")\n",
    "    else:\n",
    "        print(f\"Number of attention layers: {len(outputs.attentions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf60c0a6-79ac-42a7-89ff-af70bef8e04d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05557716-1705-4748-82a9-ecbb71e93f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
